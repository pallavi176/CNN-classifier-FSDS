{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f42f853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import urllib.request as req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3598040b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\pallavi.saxena\\Documents\\Mine\\iNeuron\\FullStackDataScienceNovember2021\\FastTrack\\3.DataScienceMasters\\2.DL\\1.FLive\\Lecture16_NewCNNclassification\\Codebase\\CNN-classifier-FSDS\\env\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading tqdm-4.63.1-py2.py3-none-any.whl (76 kB)\n",
      "     ---------------------------------------- 76.6/76.6 KB 1.4 MB/s eta 0:00:00\n",
      "Collecting colorama\n",
      "  Using cached colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Installing collected packages: colorama, tqdm\n",
      "Successfully installed colorama-0.4.4 tqdm-4.63.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61e9bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_URL = \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e46cdb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "DESTINATION = \"data\"\n",
    "os.makedirs(DESTINATION, exist_ok=True)\n",
    "data_file = \"data.zip\"\n",
    "\n",
    "DESTINATION_ZIP_PATH = os.path.join(DESTINATION, data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5f925f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename, headers = req.urlretrieve(SOURCE_URL, DESTINATION_ZIP_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c14b299e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data\\\\data.zip'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9e4eb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=DESTINATION_ZIP_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e18b11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content-Type: application/octet-stream\n",
      "Accept-Ranges: bytes\n",
      "Server: Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0\n",
      "x-ms-blob-content-md5: l2WJyK3tt5/f2azyQ9eE8w==\n",
      "Last-Modified: Sat, 13 Oct 2018 12:14:22 GMT\n",
      "ETag: \"0x8D6310568FD1DF6\"\n",
      "Content-Length: 824894548\n",
      "Date: Sun, 03 Apr 2022 02:39:53 GMT\n",
      "Connection: close\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eef3f46b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\pallavi.saxena\\\\Documents\\\\Mine\\\\iNeuron\\\\FullStackDataScienceNovember2021\\\\FastTrack\\\\3.DataScienceMasters\\\\2.DL\\\\1.FLive\\\\Lecture16_NewCNNclassification\\\\Codebase\\\\CNN-classifier-FSDS\\\\notebook'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27953f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile(filename,\"r\") as zip_f:\n",
    "    zip_f.extractall('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5b12816",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_DATA_DIRS = [\"Cat\", \"Dog\"]\n",
    "PARENT_DIR = os.path.join(\"data\",\"PetImages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be138f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "076f3b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import imghdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ed4a359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Pillow\n",
      "  Downloading Pillow-9.1.0-cp37-cp37m-win_amd64.whl (3.3 MB)\n",
      "     ---------------------------------------- 3.3/3.3 MB 7.4 MB/s eta 0:00:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\pallavi.saxena\\Documents\\Mine\\iNeuron\\FullStackDataScienceNovember2021\\FastTrack\\3.DataScienceMasters\\2.DL\\1.FLive\\Lecture16_NewCNNclassification\\Codebase\\CNN-classifier-FSDS\\env\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Installing collected packages: Pillow\n",
      "Successfully installed Pillow-9.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f7e1cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\PIL\\TiffImagePlugin.py:811: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    }
   ],
   "source": [
    "for dirs in os.listdir(PARENT_DIR):\n",
    "    full_path_data_dir = os.path.join(PARENT_DIR, dirs)\n",
    "    for imgs in os.listdir(full_path_data_dir):\n",
    "        path_to_img = os.path.join(full_path_data_dir, imgs)\n",
    "        try:\n",
    "            img = Image.open(path_to_img)\n",
    "            img.verify()               \n",
    "            #print(f\"{path_to_img} is verified\")\n",
    "        except Exception as e:\n",
    "            print(f\"{path_to_img} is bad !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4066bd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "BAD_DATA_DIR = \"bad_data\"\n",
    "os.makedirs(BAD_DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48c06935",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirs in os.listdir(PARENT_DIR):\n",
    "    full_path_data_dir = os.path.join(PARENT_DIR, dirs)\n",
    "    for imgs in os.listdir(full_path_data_dir):\n",
    "        path_to_img = os.path.join(full_path_data_dir, imgs)\n",
    "        try:\n",
    "            img = Image.open(path_to_img)\n",
    "            img.verify()               \n",
    "            #print(f\"{path_to_img} is verified\")\n",
    "        except Exception as e:\n",
    "            print(f\"{path_to_img} is bad !\")\n",
    "            bad_data_path = os.path.join(BAD_DATA_DIR, imgs)\n",
    "            shutil.move(path_to_img, bad_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c9f4376",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (180, 180)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "812417f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24998 files belonging to 2 classes.\n",
      "Using 19999 files for training.\n",
      "Found 24998 files belonging to 2 classes.\n",
      "Using 4999 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    PARENT_DIR,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=42,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    PARENT_DIR,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4603bbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving logs at: logs\\fit\\Sun_Apr__3_090652_2022\n"
     ]
    }
   ],
   "source": [
    "### Create a log dir for tensorboard logs\n",
    "\n",
    "import time\n",
    "\n",
    "def get_log_path(base_log_dir=os.path.join(\"logs\",\"fit\")):\n",
    "    uniqueName = time.asctime().replace(\" \", \"_\").replace(\":\", \"\")\n",
    "    log_path = os.path.join(base_log_dir, uniqueName)\n",
    "    print(f\"saving logs at: {log_path}\")\n",
    "    return log_path\n",
    "\n",
    "log_dir = get_log_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe15a752",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer = tf.summary.create_file_writer(logdir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e54bac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 180, 180, 3) tf.Tensor([1 1 1 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 1 1 1 0 0], shape=(32,), dtype=int32)\n",
      "(32, 180, 180, 3) tf.Tensor([0 0 1 0 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 1 0 1 1 1 1 0], shape=(32,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_ds.take(2):\n",
    "    print(images.shape, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e09af4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 180, 180, 3) tf.Tensor([0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0], shape=(32,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_ds.take(1):\n",
    "    print(images.shape, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de61e4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 180, 180, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6052982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f55c92cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with file_writer.as_default():\n",
    "    images = np.reshape(images[10:30], (-1, 180, 180, 3))\n",
    "\n",
    "    tf.summary.image(\"20 samples\", images, max_outputs=25, step=0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "400785e8",
   "metadata": {},
   "source": [
    "Go to terminal in activate environment\n",
    "tensorboard --logdir=notebook/logs/fit/\n",
    "tensorboard  --logdir=notebook\\logs\\fit\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6a42676",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9521823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-48e4d4f667da53ed\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-48e4d4f667da53ed\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=notebook/logs/fit/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f00225",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tensorboard/get_started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "edf4fd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 180, 180, 3) tf.Tensor([0 1 1 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0], shape=(32,), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 180, 180, 3])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create a log dir for tensorboard logs\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def get_log_path(base_log_dir=os.path.join(\"logs\",\"fit\")):\n",
    "    uniqueName = time.asctime().replace(\" \", \"_\").replace(\":\", \"\")\n",
    "    log_path = os.path.join(base_log_dir, uniqueName)\n",
    "    print(f\"saving logs at: {log_path}\")\n",
    "    return log_path\n",
    "\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(images.shape, labels)\n",
    "    \n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2de6402e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving logs at: logs\\fit\\Sun_Apr__3_094207_2022\n"
     ]
    }
   ],
   "source": [
    "log_dir = get_log_path()\n",
    "\n",
    "file_writer = tf.summary.create_file_writer(logdir=log_dir)\n",
    "\n",
    "with file_writer.as_default():\n",
    "    images = np.array(images)       ##[10:30], (-1, 180, 180, 3))\n",
    "\n",
    "    tf.summary.image(\"20 samples\", images, max_outputs=25, step=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7358db9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 180, 180, 3) tf.Tensor([0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 1 1 0 0 0 1 0 1 1 1], shape=(32,), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 180, 180, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create a log dir for tensorboard logs\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def get_log_path(base_log_dir=os.path.join(\"logs\",\"fit\")):\n",
    "    uniqueName = time.asctime().replace(\" \", \"_\").replace(\":\", \"\")\n",
    "    log_path = os.path.join(base_log_dir, uniqueName)\n",
    "    print(f\"saving logs at: {log_path}\")\n",
    "    return log_path\n",
    "\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(images.shape, labels)\n",
    "    \n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f43fed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving logs at: logs\\fit\\Sun_Apr__3_100128_2022\n"
     ]
    }
   ],
   "source": [
    "log_dir = get_log_path()\n",
    "\n",
    "file_writer = tf.summary.create_file_writer(logdir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e04f9d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with file_writer.as_default():\n",
    "    images = np.array(images) ##[10:30], (-1, 180, 180, 3))\n",
    "\n",
    "    tf.summary.image(\"samples\", images.astype(\"uint8\"), max_outputs=25, step=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765a1447",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard --logdir=notebook/logs/fit/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c071e6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6000 * 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13734ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
